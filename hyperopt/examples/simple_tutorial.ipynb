{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Tutorial using `hyperopt`\n",
    "\n",
    "In this simple tutorial, we show how to use hyperopt on the well known Iris dataset from scikit-learn. We use a neural network as the model, but any model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.model_selection import fit_model_with_grid_search\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Network imports (simple sklearn Neural Network)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Silence neural network SGD convergence warnings.\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [\"constant\", \"adaptive\"],\n",
    "    'hidden_layer_sizes': [(100,20), (500,20)],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'warm_start': [True, False],\n",
    "    'momentum': [0.9, 0.8],\n",
    "    'learning_rate_init': [.001, .01, .0001],\n",
    "    'max_iter': [50],\n",
    "    'random_state': [0],\n",
    "    'activation': ['relu'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set sizes: 73 (train), 32 (val), 45 (test)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris[\"data\"], iris[\"target\"], test_size = 0.3, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train,test_size = 0.3, random_state = 0)\n",
    "print('Set sizes:', len(X_train), '(train),', len(X_val), '(val),', len(X_test), '(test)')\n",
    "\n",
    "# Normalize data \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_val = scaler.transform(X_val)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-search time comparison using validation set versus cross-validation. \n",
    "### The hyperopt package automatically distributes work on all CPU threads regardless of if you use a validation set or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First let's try the neural network with default parameters.\n",
      "\n",
      "TEST SCORE (default parameters) 0.8444\n",
      "VALIDATION SCORE (default parameters) 0.9062\n"
     ]
    }
   ],
   "source": [
    "print(\"First let's try the neural network with default parameters.\")\n",
    "default = MLPClassifier(max_iter=50, random_state=0)\n",
    "default.fit(X_train, y_train)\n",
    "test_score = round(default.score(X_test, y_test), 4)\n",
    "val_score = round(default.score(X_val, y_val), 4)\n",
    "print('\\nTEST SCORE (default parameters)', test_score)\n",
    "print('VALIDATION SCORE (default parameters)', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid-search using a validation set.\n",
      " -------------------------------------------------------------------------------\n",
      "Running 8 job(s) on 12 thread(s).\n",
      "CPU times: user 48.7 ms, sys: 73.4 ms, total: 122 ms\n",
      "Wall time: 4.2 s\n",
      "\n",
      "TEST SCORE (hyper-parameter optimization with validation set) 0.9556\n",
      "\n",
      "VALIDATION SCORE (hyper-parameter optimization with validation set) 0.9375\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=50, random_state=0)\n",
    "print(\"Grid-search using a validation set.\\n\",\"-\"*79)\n",
    "%time trained_clf_val = fit_model_with_grid_search(model, X_train, y_train, param_grid, X_val, y_val)\n",
    "test_score = round(trained_clf_val.score(X_test, y_test), 4)\n",
    "val_score = round(trained_clf_val.score(X_val, y_val), 4)\n",
    "print('\\nTEST SCORE (hyper-parameter optimization with validation set)', test_score)\n",
    "print('\\nVALIDATION SCORE (hyper-parameter optimization with validation set)', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Let's see how long grid-search takes to run when we don't use a validation set.\n",
      "Grid-search using cross-validation.\n",
      " -------------------------------------------------------------------------------\n",
      "CPU times: user 475 ms, sys: 82.7 ms, total: 558 ms\n",
      "Wall time: 12.7 s\n",
      "\n",
      "TEST SCORE (hyper-parameter optimization with cross-validation) 0.9556\n",
      "\n",
      "VALIDATION SCORE (hyper-parameter optimization with cross-validation) 0.9375\n",
      "\n",
      "Note that although its slower, cross-validation has many benefits (e.g. uses all\n",
      "your training data). Thats why hyperopt also supports cross-validation when no validation \n",
      "set is provided as in the example above.\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=50, random_state=0)\n",
    "print(\"\\n\\nLet's see how long grid-search takes to run when we don't use a validation set.\")\n",
    "print(\"Grid-search using cross-validation.\\n\",\"-\"*79)\n",
    "%time trained_clf_cv = fit_model_with_grid_search(model, X_train, y_train, param_grid, cv_folds = 5)\n",
    "test_score = round(trained_clf_cv.score(X_test, y_test), 4)\n",
    "val_score = round(trained_clf_cv.score(X_val, y_val), 4)\n",
    "print('\\nTEST SCORE (hyper-parameter optimization with cross-validation)', test_score)\n",
    "print('\\nVALIDATION SCORE (hyper-parameter optimization with cross-validation)', val_score)\n",
    "print('''\\nNote that although its slower, cross-validation has many benefits (e.g. uses all\n",
    "your training data). Thats why hyperopt also supports cross-validation when no validation \n",
    "set is provided as in the example above.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
